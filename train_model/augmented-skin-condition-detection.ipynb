{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9154979,"sourceType":"datasetVersion","datasetId":5530427}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport os\nfrom tqdm import tqdm\nfrom tensorflow.keras import layers, models\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-09-16T18:13:44.188314Z","iopub.execute_input":"2024-09-16T18:13:44.188669Z","iopub.status.idle":"2024-09-16T18:13:58.490020Z","shell.execute_reply.started":"2024-09-16T18:13:44.188629Z","shell.execute_reply":"2024-09-16T18:13:58.489076Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Create dataset from image data","metadata":{}},{"cell_type":"code","source":"images_root_path = '/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions'\nlist_disease_labels = os.listdir(images_root_path)\nprint(\"Skin diseases present in the dataset: \",','.join(list_disease_labels))\nfor disease_label in list_disease_labels:\n    images = os.listdir(f'{images_root_path}/{disease_label}')\n    print(f'\\nDisease label: {disease_label}\\nImaga files counts: {len(images)}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:13:58.491688Z","iopub.execute_input":"2024-09-16T18:13:58.492215Z","iopub.status.idle":"2024-09-16T18:13:59.721111Z","shell.execute_reply.started":"2024-09-16T18:13:58.492180Z","shell.execute_reply":"2024-09-16T18:13:59.720247Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Skin diseases present in the dataset:  Eczema,Acne,Milia,Rosacea,Keratosis,Carcinoma\n\nDisease label: Eczema\nImaga files counts: 399\n\n\nDisease label: Acne\nImaga files counts: 399\n\n\nDisease label: Milia\nImaga files counts: 399\n\n\nDisease label: Rosacea\nImaga files counts: 399\n\n\nDisease label: Keratosis\nImaga files counts: 399\n\n\nDisease label: Carcinoma\nImaga files counts: 399\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def fetch_image_data():\n    combined_images_path,disese_labels = [],[]\n    for disease_label in list_disease_labels:\n        current_disease_images_path = os.listdir(f'{images_root_path}/{disease_label}')\n        current_disease_images_path = [f'{images_root_path}/{disease_label}/{cur_image}' for cur_image in current_disease_images_path]\n        combined_images_path.extend(current_disease_images_path)\n        disese_labels.extend([disease_label]*len(current_disease_images_path))\n    print(f\"Count images: {len(combined_images_path)}\")\n    print(f\"Count labels: {len(disese_labels)}\")\n    # Shuffling data\n    image_paths_shuffled,label_shuffled = [],[]\n    permutation = np.random.permutation(len(combined_images_path))\n    image_paths_shuffled = [combined_images_path[i] for i in permutation]\n    label_shuffled = [disese_labels[i] for i in permutation]\n    return image_paths_shuffled,label_shuffled\n\nlist_images_paths, list_labels = fetch_image_data()\nprint(\"First 5 images:\",list_images_paths[:5])\nprint(\"First 5 labels:\",list_labels[:5])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:13:59.722466Z","iopub.execute_input":"2024-09-16T18:13:59.723276Z","iopub.status.idle":"2024-09-16T18:13:59.738246Z","shell.execute_reply.started":"2024-09-16T18:13:59.723230Z","shell.execute_reply":"2024-09-16T18:13:59.737371Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Count images: 2394\nCount labels: 2394\nFirst 5 images: ['/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions/Eczema/Eczema_105.jpg', '/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions/Eczema/Eczema_391.jpg', '/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions/Rosacea/Rosacea_5.jpg', '/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions/Carcinoma/Carcinoma_356.jpg', '/kaggle/input/augmented-skin-conditions-image-dataset/Skin_Conditions/Carcinoma/Carcinoma_250.jpg']\nFirst 5 labels: ['Eczema', 'Eczema', 'Rosacea', 'Carcinoma', 'Carcinoma']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to preprocess images (read, resize and normalize)\ndef preprocess_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [224, 224])  \n    return image\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:13:59.740652Z","iopub.execute_input":"2024-09-16T18:13:59.740964Z","iopub.status.idle":"2024-09-16T18:13:59.746594Z","shell.execute_reply.started":"2024-09-16T18:13:59.740931Z","shell.execute_reply":"2024-09-16T18:13:59.745790Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Function to load image and label\ndef load_image_and_label(image_path,label):\n    image = preprocess_image(image_path)\n    label = tf.reduce_min(tf.where(tf.equal(list_disease_labels, label)))\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:13:59.747788Z","iopub.execute_input":"2024-09-16T18:13:59.748066Z","iopub.status.idle":"2024-09-16T18:13:59.755983Z","shell.execute_reply.started":"2024-09-16T18:13:59.748036Z","shell.execute_reply":"2024-09-16T18:13:59.755108Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Main function\ndef build_dataset(batch_size = 32):\n    image_paths,labels = fetch_image_data()\n    # Create TensorFlow dataset\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths,labels))\n    dataset = dataset.map(lambda image_path, label: load_image_and_label(image_path,label))\n    dataset.shuffle(len(image_paths))\n    return dataset.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:13:59.757018Z","iopub.execute_input":"2024-09-16T18:13:59.757541Z","iopub.status.idle":"2024-09-16T18:13:59.769974Z","shell.execute_reply.started":"2024-09-16T18:13:59.757496Z","shell.execute_reply":"2024-09-16T18:13:59.769072Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset = build_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:13:59.771402Z","iopub.execute_input":"2024-09-16T18:13:59.772131Z","iopub.status.idle":"2024-09-16T18:14:00.787029Z","shell.execute_reply.started":"2024-09-16T18:13:59.772090Z","shell.execute_reply":"2024-09-16T18:14:00.786217Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Count images: 2394\nCount labels: 2394\n","output_type":"stream"}]},{"cell_type":"code","source":"\nprint(\"Dataset spec :\",tf.data.DatasetSpec.from_value(dataset))\ndataset_size = dataset.cardinality().numpy()\nprint(\"Dataset size :\", dataset_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:14:00.788271Z","iopub.execute_input":"2024-09-16T18:14:00.788982Z","iopub.status.idle":"2024-09-16T18:14:00.795142Z","shell.execute_reply.started":"2024-09-16T18:14:00.788935Z","shell.execute_reply":"2024-09-16T18:14:00.794112Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Dataset spec : DatasetSpec((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None)), TensorShape([]))\nDataset size : 75\n","output_type":"stream"}]},{"cell_type":"code","source":"train_size,test_size = int(0.8*dataset_size),int(0.1*dataset_size)\ntrain_dataset = dataset.take(train_size)\nremaining_dataset = dataset.skip(train_size)\ntest_dataset = remaining_dataset.take(test_size)\nval_dataset = remaining_dataset.skip(test_size)\n\n# Optional: Prefetch for performance\ntrain_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\nval_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n\nprint(\"Train dataset spec :\",tf.data.DatasetSpec.from_value(train_dataset))\nprint(\"Eval dataset spec :\",tf.data.DatasetSpec.from_value(val_dataset))\nprint(\"Test dataset spec :\",tf.data.DatasetSpec.from_value(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:14:00.796324Z","iopub.execute_input":"2024-09-16T18:14:00.796628Z","iopub.status.idle":"2024-09-16T18:14:00.818693Z","shell.execute_reply.started":"2024-09-16T18:14:00.796588Z","shell.execute_reply":"2024-09-16T18:14:00.817806Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Train dataset spec : DatasetSpec((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None)), TensorShape([]))\nEval dataset spec : DatasetSpec((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None)), TensorShape([]))\nTest dataset spec : DatasetSpec((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None)), TensorShape([]))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building CNN model","metadata":{}},{"cell_type":"code","source":"def classification_model(input_shape=(224, 224, 3), labels=list_disease_labels):\n    num_classes = len(list_disease_labels)\n    model = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(256, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n    ])\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n    # Compile the model\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-16T19:14:57.898931Z","iopub.execute_input":"2024-09-16T19:14:57.899302Z","iopub.status.idle":"2024-09-16T19:14:57.907782Z","shell.execute_reply.started":"2024-09-16T19:14:57.899266Z","shell.execute_reply":"2024-09-16T19:14:57.906809Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"epochs = 50\nmodel = classification_model()\n\n# Add early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  \n    patience=3,  \n    start_from_epoch=10,\n    restore_best_weights=True  \n)\n\n#training model\nhistory = model.fit(train_dataset,validation_data=val_dataset,epochs = epochs, callbacks=[early_stopping])\n\ntraining_loss = history.history['loss']\ntraining_accuracy = history.history['accuracy']\nval_loss = history.history['val_loss']\nval_accuracy = history.history['val_accuracy']\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T19:15:03.576412Z","iopub.execute_input":"2024-09-16T19:15:03.577082Z","iopub.status.idle":"2024-09-16T19:16:36.746918Z","shell.execute_reply.started":"2024-09-16T19:15:03.577040Z","shell.execute_reply":"2024-09-16T19:16:36.745988Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.2063 - loss: 27.3431 - val_accuracy: 0.3480 - val_loss: 1.5749\nEpoch 2/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.3634 - loss: 1.5266 - val_accuracy: 0.3360 - val_loss: 1.6252\nEpoch 3/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.4666 - loss: 1.3332 - val_accuracy: 0.5280 - val_loss: 1.1806\nEpoch 4/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.5452 - loss: 1.1905 - val_accuracy: 0.4600 - val_loss: 1.3764\nEpoch 5/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.6291 - loss: 0.9766 - val_accuracy: 0.5640 - val_loss: 1.2688\nEpoch 6/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.6935 - loss: 0.7966 - val_accuracy: 0.4680 - val_loss: 1.3975\nEpoch 7/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.7103 - loss: 0.7998 - val_accuracy: 0.5320 - val_loss: 1.5424\nEpoch 8/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.7651 - loss: 0.6988 - val_accuracy: 0.5760 - val_loss: 1.4421\nEpoch 9/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.8069 - loss: 0.5317 - val_accuracy: 0.5920 - val_loss: 1.5020\nEpoch 10/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.8456 - loss: 0.4654 - val_accuracy: 0.6040 - val_loss: 1.3280\nEpoch 11/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.8636 - loss: 0.4085 - val_accuracy: 0.5280 - val_loss: 1.8480\nEpoch 12/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.8631 - loss: 0.4007 - val_accuracy: 0.5640 - val_loss: 1.8187\nEpoch 13/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.8669 - loss: 0.3870 - val_accuracy: 0.5800 - val_loss: 2.1168\nEpoch 14/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.8759 - loss: 0.3866 - val_accuracy: 0.6120 - val_loss: 1.8482\nEpoch 15/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.8279 - loss: 0.5727 - val_accuracy: 0.5040 - val_loss: 1.9626\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_dataset)\nprint(\"Test loss:\",test_loss)\nprint(\"Test accuracy:\",test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T19:16:41.168884Z","iopub.execute_input":"2024-09-16T19:16:41.169261Z","iopub.status.idle":"2024-09-16T19:16:43.824805Z","shell.execute_reply.started":"2024-09-16T19:16:41.169226Z","shell.execute_reply":"2024-09-16T19:16:43.823855Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.5931 - loss: 2.0786\nTest loss: 2.0905330181121826\nTest accuracy: 0.5758928656578064\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the model\nfinetuned_model.save('cnn_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T19:17:26.386937Z","iopub.execute_input":"2024-09-16T19:17:26.387321Z","iopub.status.idle":"2024-09-16T19:17:26.916540Z","shell.execute_reply.started":"2024-09-16T19:17:26.387285Z","shell.execute_reply":"2024-09-16T19:17:26.915519Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning Resnet50 model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.applications import ResNet50\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:25:37.999818Z","iopub.execute_input":"2024-09-16T18:25:38.000480Z","iopub.status.idle":"2024-09-16T18:25:38.018908Z","shell.execute_reply.started":"2024-09-16T18:25:38.000441Z","shell.execute_reply":"2024-09-16T18:25:38.017924Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(6, activation='softmax')(x)\ndef lr_scheduler(epoch, lr):\n    if epoch%10 ==9:\n        return 0.8*lr\n    else:\n        return lr\nfinetuned_model = Model(inputs=base_model.input, outputs=predictions)\nfinetuned_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = lr_scheduler(0,0.01) ),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:25:46.150848Z","iopub.execute_input":"2024-09-16T18:25:46.151217Z","iopub.status.idle":"2024-09-16T18:25:48.559650Z","shell.execute_reply.started":"2024-09-16T18:25:46.151183Z","shell.execute_reply":"2024-09-16T18:25:48.558764Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 50\nmodel = classification_model()\n\n# Add early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  \n    patience=3,  \n    start_from_epoch=10,\n    restore_best_weights=True  \n)\n\n# training model\nhistory = finetuned_model.fit(train_dataset,validation_data=val_dataset,epochs = epochs, callbacks=[early_stopping])\n\ntraining_loss = history.history['loss']\ntraining_accuracy = history.history['accuracy']\nval_loss = history.history['val_loss']\nval_accuracy = history.history['val_accuracy']\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:25:48.561180Z","iopub.execute_input":"2024-09-16T18:25:48.561492Z","iopub.status.idle":"2024-09-16T18:28:17.072276Z","shell.execute_reply.started":"2024-09-16T18:25:48.561459Z","shell.execute_reply":"2024-09-16T18:28:17.071214Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1726511155.516291     101 service.cc:145] XLA service 0x7c25dc0498d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1726511155.516366     101 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1726511155.516372     101 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 2/60\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.1641 - loss: 9.6955  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1726511163.424069     101 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 278ms/step - accuracy: 0.4455 - loss: 13.3668 - val_accuracy: 0.7560 - val_loss: 0.6706\nEpoch 2/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.7557 - loss: 0.7149 - val_accuracy: 0.8360 - val_loss: 0.4456\nEpoch 3/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.8014 - loss: 0.5386 - val_accuracy: 0.8520 - val_loss: 0.4146\nEpoch 4/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.8408 - loss: 0.4843 - val_accuracy: 0.8760 - val_loss: 0.4069\nEpoch 5/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 141ms/step - accuracy: 0.8514 - loss: 0.4244 - val_accuracy: 0.8800 - val_loss: 0.3463\nEpoch 6/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - accuracy: 0.8494 - loss: 0.4734 - val_accuracy: 0.8680 - val_loss: 0.4218\nEpoch 7/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - accuracy: 0.8627 - loss: 0.3950 - val_accuracy: 0.8720 - val_loss: 0.3759\nEpoch 8/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - accuracy: 0.8626 - loss: 0.4338 - val_accuracy: 0.8800 - val_loss: 0.3677\nEpoch 9/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.8600 - loss: 0.4060 - val_accuracy: 0.8800 - val_loss: 0.3774\nEpoch 10/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.8375 - loss: 0.4743 - val_accuracy: 0.8880 - val_loss: 0.3726\nEpoch 11/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - accuracy: 0.8666 - loss: 0.3938 - val_accuracy: 0.8720 - val_loss: 0.3818\nEpoch 12/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - accuracy: 0.8506 - loss: 0.5054 - val_accuracy: 0.9040 - val_loss: 0.3508\nEpoch 13/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 137ms/step - accuracy: 0.8741 - loss: 0.4012 - val_accuracy: 0.8720 - val_loss: 0.4207\nEpoch 14/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - accuracy: 0.8700 - loss: 0.3693 - val_accuracy: 0.8760 - val_loss: 0.4199\nEpoch 15/50\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.8571 - loss: 0.3969 - val_accuracy: 0.8880 - val_loss: 0.3616\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = finetuned_model.evaluate(test_dataset)\nprint(\"Test loss:\",test_loss)\nprint(\"Test accuracy:\",test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:28:17.073432Z","iopub.execute_input":"2024-09-16T18:28:17.073756Z","iopub.status.idle":"2024-09-16T18:28:20.092141Z","shell.execute_reply.started":"2024-09-16T18:28:17.073706Z","shell.execute_reply":"2024-09-16T18:28:20.091320Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.8920 - loss: 0.5808\nTest loss: 0.4540325999259949\nTest accuracy: 0.9017857313156128\n","output_type":"stream"}]},{"cell_type":"code","source":"finetuned_model.save('resnet_50_finetuned.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:28:20.093825Z","iopub.execute_input":"2024-09-16T18:28:20.094134Z","iopub.status.idle":"2024-09-16T18:28:20.538771Z","shell.execute_reply.started":"2024-09-16T18:28:20.094101Z","shell.execute_reply":"2024-09-16T18:28:20.537617Z"},"trusted":true},"execution_count":17,"outputs":[]}]}